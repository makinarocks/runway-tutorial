# Object Detection

<h4 align="center">
    <p>
        <b>í•œêµ­ì–´</b> |
        <a href="README_en.md">English</a>
    <p>
</h4>

<h3 align="center">
    <p>The MLOps platform to Let your AI run</p>
</h3>

## Introduction

Runwayì— í¬í•¨ëœ Linkë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.  
ì‘ì„±í•œ ëª¨ë¸ í•™ìŠµ ì½”ë“œë¥¼ ì¬í•™ìŠµì— í™œìš©í•˜ê¸° ìœ„í•´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

> ğŸ“˜ ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ì•„ë˜ì˜ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> ì•„ë˜ì˜ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ì‹¤í–‰í•  ê²½ìš°, "my-detection-model" ì´ë¦„ì˜ ëª¨ë¸ì´ ìƒì„±ë˜ì–´ Runwayì— ì €ì¥ë©ë‹ˆë‹¤.
>
> **[object detection notebook](https://drive.google.com/uc?export=download&id=1WgdswAqXZtRE-BMJXpiFIBYHV-oboV4F)**

![link notebook](../../assets/object_detection/link_pipeline.png)

## Runway

### ë°ì´í„°ì…‹ ìƒì„±

> ğŸ“˜ ì´ íŠœí† ë¦¬ì–¼ì€ COCO ë°ì´í„° ì…‹ì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©í•´ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
>
> COCO ìƒ˜í”Œ ë°ì´í„°ì…‹ì€ ì•„ë˜ í•­ëª©ì„ í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> **[coco-sample-dataset.zip](https://drive.google.com/uc?export=download&id=1TrM3y8aRRmaYnIlDI902p73Lsw0XC89B)**

1. Runway í”„ë¡œì íŠ¸ ë©”ë‰´ì—ì„œ ë°ì´í„°ì…‹ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
2. ë°ì´í„°ì…‹ í˜ì´ì§€ì—ì„œ ì‹ ê·œ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì…‹ í˜ì´ì§€ì˜ ìš°ì¸¡ ìƒë‹¨ `Create Dataset`ì„ í´ë¦­í•©ë‹ˆë‹¤.
4. ì €ì¥í•˜ëŠ” ë°ì´í„°ì…‹ì˜ ì´ë¦„ê³¼ ì„¤ëª…ì„ ì…ë ¥í•©ë‹ˆë‹¤.
5. ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ì˜ ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤.
6. ë°ì´í„°ì…‹ìœ¼ë¡œ ìƒì„±í•  íŒŒì¼ë“¤(jpg, json)ì„ íŒŒì¼ íƒìƒ‰ê¸°ë¡œ ì„ íƒí•˜ê±°ë‚˜, Drag&Dropìœ¼ë¡œ ì…ë ¥í•©ë‹ˆë‹¤.
7. `Create`ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.

## Link

### íŒ¨í‚¤ì§€ ì„¤ì¹˜

1. íŠœí† ë¦¬ì–¼ì—ì„œ ì‚¬ìš©í•  íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
    ```python
    !pip install torch torchvision Pillow seaborn torchmetrics
    ```

### ë°ì´í„°

#### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

> ğŸ“˜ ë°ì´í„° ì„¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°€ì´ë“œëŠ” **[ë°ì´í„° ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°](https://docs.mrxrunway.ai/docs/ë°ì´í„°-ì„¸íŠ¸-ê°€ì ¸ì˜¤ê¸°)** ê°€ì´ë“œ ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. Runway ì½”ë“œ ìŠ¤ë‹ˆí« ë©”ë‰´ì˜ **import dataset**ì„ ì´ìš©í•´ í”„ë¡œì íŠ¸ì— ë“±ë¡ë˜ì–´ ìˆëŠ” ë°ì´í„°ì…‹ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
2. ìƒì„±í•œ ë°ì´í„°ì…‹ì„ ì„ íƒí•´ì„œ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ```python
    import os
    from pycocotools.coco import COCO

    # RUNWAY_DATA_PATH was added to pipeline parameters.
    # Pipeline parameters can be used in the cell added as a pipeline component.
    # RUNWAY_DATA_PATH = "/home/jovyan/workspace/dataset/sample-coco"
    config_file = None
    for dirname, _, filenames in os.walk(RUNWAY_DATA_PATH):
        for filename in filenames:
            if filename.endswith(".json"):
                config_file = os.path.join(dirname, filename)

    if config_file is None:
        raise ValueError("Can't find config file in given dataset")

    coco = COCO(config_file)
    ```

#### ì˜ˆì œ ë°ì´í„° ì¶”ì¶œ

1. ìƒ˜í”Œ ë°ì´í„° í•˜ë‚˜ë¥¼ ì¶”ì¶œ í›„ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    ```python
    from pathlib import Path
    from matplotlib.pyplot import imshow
    from PIL import Image


    sample_image_path = Path(RUNWAY_DATA_PATH).parent / "000000000139.jpg"
    image_filename_list = [sample_image_path]

    img = Image.open(sample_image_path)
    imshow(img)
    ```

    ![sample image](../../assets/object_detection/sample_image.png)

### í•™ìŠµ

#### COCO ë°ì´í„°ì…‹

1. ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ pytorch ì—ì„œ ì œê³µí•˜ëŠ” Dataset ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ```python
    from PIL import Image
    from pathlib import Path
    from pycocotools.coco import COCO
    import torch
    from torch.utils.data import Dataset
    from torchvision import transforms as T


    def get_transforms():
        transforms = []
        transforms.append(T.ToTensor())
        return T.Compose(transforms)


    def collate_fn(batch):
        return tuple(zip(*batch))


    class COCODataset(Dataset):
        def __init__(self, data_root, coco, transforms=None):
            self.data_root = Path(data_root)
            self.transforms = transforms
            # pre-loaded variables
            self.coco = coco
            self.ids = list(sorted(self.coco.imgs.keys()))

        def __getitem__(self, index):
            ## refer to https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html
            img_id = self.ids[index]
            ann_ids = self.coco.getAnnIds(imgIds=img_id)
            ann = self.coco.loadAnns(ann_ids)
            img_path = self.data_root / self.coco.loadImgs(img_id)[0]["file_name"]
            img = Image.open(img_path)
            num_objs = len(ann)

            boxes = []
            for i in range(num_objs):
                boxes.append([
                    ann[i]["bbox"][0],
                    ann[i]["bbox"][1],
                    ann[i]["bbox"][2] + ann[i]["bbox"][0],
                    ann[i]["bbox"][3] + ann[i]["bbox"][1],
                ])

            areas = []
            for i in range(num_objs):
                areas.append(ann[i]["area"])

            target = {
                "boxes": torch.as_tensor(boxes, dtype=torch.float32),
                "labels": torch.ones((num_objs,), dtype=torch.int64),
                "image_id": torch.tensor([img_id]),
                "area": torch.as_tensor(areas, dtype=torch.float32),
                "iscrowd": torch.zeros((num_objs,), dtype=torch.int64),
            }

            ## transform image
            if self.transforms is not None:
                img = self.transforms(img)

            return img, target

        def __len__(self):
            return len(self.ids)
    ```

2. ì„ ì–¸í•œ ë°ì´í„°ë¥¼ ì´ìš©í•´ ë°ì´í„° ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ```python
    from torch.utils.data import DataLoader

    ## Define Train dataset
    data_root = Path(RUNWAY_DATA_PATH).parent
    dataset = COCODataset(data_root, coco, get_transforms())

    data_loader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=True,
        num_workers=4,
        collate_fn=collate_fn
    )
    ```

### ëª¨ë¸ ì„ ì–¸

1. í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ ì–¸í•©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ì—ì„œëŠ” pytorch ì˜ `fasterrcnn_resnet50_fpn` ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    ```python
    import torch
    from torchvision.models.detection import fasterrcnn_resnet50_fpn

    ## Define local variables
    print(torch.cuda.is_available())
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

    ## Define training model
    model = fasterrcnn_resnet50_fpn(weights="DEFAULT").to(device)
    ```

### ëª¨ë¸ í•™ìŠµ

> ğŸ“˜ Link íŒŒë¼ë¯¸í„° ë“±ë¡ ê°€ì´ë“œëŠ” **[íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ì„¤ì •](https://dash.readme.com/project/makinarocks-runway/docs/íŒŒì´í”„ë¼ì¸-íŒŒë¼ë¯¸í„°-ì„¤ì •)** ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ëª¨ë¸ì„ í•™ìŠµí•  Epoch ì„ ì„¤ì •í•  ìˆ˜ ìˆë„ë¡ Link íŒŒë¼ë¯¸í„°ë¡œ N_EPOCHS ì— 1ì„ ë“±ë¡í•©ë‹ˆë‹¤.
2. ì„ ì–¸í•œ ëª¨ë¸ì„ ìœ„ì—ì„œ ë§Œë“  ë°ì´í„° ë¡œë”ë¥¼ í†µí•´ í•™ìŠµí•˜ê³  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

    ```python
    import torch.optim as optim
    from torchmetrics.detection import MeanAveragePrecision

    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.SGD(params, lr=1e-5)

    model.train()
    for epoch in range(N_EPOCHS):
        for imgs, annotations in data_loader:
            imgs = list(img.to(device) for img in imgs)
            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]
            loss_dict = model(imgs, annotations)
            losses = sum(loss for loss in loss_dict.values())

            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

    map_metric = MeanAveragePrecision().to(device)
    model.eval()
    with torch.no_grad():
        preds = []
        annos = []
        for imgs, annotations in data_loader:
            pred = model(list(img.to(device) for img in imgs))
            anno = [{k: v.to(device) for k, v in t.items()} for t in annotations]
            preds.extend(pred)
            annos.extend(anno)

    map_metric.update(preds, annos)
    map_score = map_metric.compute()

    torch.cuda.empty_cache()
    ```

### ëª¨ë¸ ì¶”ë¡ 

#### ëª¨ë¸ ë©í•‘ í´ë˜ìŠ¤ ì„ ì–¸

1. í•™ìŠµëœ ëª¨ë¸ì„ ì„œë¹™í•  ìˆ˜ ìˆë„ë¡ ModelWrapperë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    ```python
    import io
    import base64

    import torch
    import pandas as pd
    import numpy as np
    from torchvision import transforms
    from PIL import Image


    class ModelWrapper:
        def __init__(self, model, device):
            self.model = model
            self.device = device

        def bytesarray_to_tensor(self, bytes_array: str):
            ## input : "utf-8" decoded bytes_array
            encoded_bytes_array = bytes_array.encode("utf-8")
            ## decode encoded_bytes_array with ascii code
            img_64_decode = base64.b64decode(encoded_bytes_array)
            ## get image file and transform to tensor
            image_from_bytes = Image.open(io.BytesIO(img_64_decode))
            return transforms.ToTensor()(image_from_bytes).to(self.device)

        def tensor_to_bytesarray(self, tensor: torch.Tensor):
            tensor_bytes_array = tensor.detach().cpu().numpy().tobytes()
            tensor_64_encode = base64.b64encode(tensor_bytes_array)
            bytes_array = tensor_64_encode.decode("utf-8")
            return bytes_array

        @torch.no_grad()
        def predict(self, df):
            self.model.eval()
            ## df is 1-d dataframe with bytes array
            tensor_list = list((map(self.bytesarray_to_tensor, df.squeeze(axis=1).to_list())))
            pred = self.model(tensor_list)
            result = pd.DataFrame(pred).applymap(lambda x: self.tensor_to_bytesarray(x))
            torch.cuda.empty_cache()
            return result

        def revert_predict_to_array(self, pred):
            pred_decode = pred.applymap(base64.b64decode)
            for key in pred_decode.keys():
                if key == "labels":
                    pred_decode[key] = pred_decode[key].apply(lambda x: np.frombuffer(x, dtype=int))
                elif key == "boxes":
                    pred_decode[key] = pred_decode[key].apply(lambda x: np.frombuffer(x, dtype=np.float32).reshape(-1, 4))
                else:
                    pred_decode[key] = pred_decode[key].apply(lambda x: np.frombuffer(x, dtype=np.float32))
            return pred_decode
    ```

2. í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì„ ModelWrapper ë¡œ ëª¨ë¸ì„ ë©í•‘í•©ë‹ˆë‹¤.

    ```python
    model = model.cpu()
    device = "cpu"
    serve_model = ModelWrapper(model=model, device=device)
    ```

#### ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ë¡ 

1. Runway ì—ì„œëŠ” API ì„œë¹™ì„ ìœ„í•œ ì…ë ¥ê³¼ ì¶œë ¥ì„ Dataframe í˜•ì‹ë§Œ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ bytearray ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    ```python
    import base64
    import pandas as pd


    def convert_image_to_bytearray(img_binary):
        image_64_encode = base64.b64encode(img_binary)
        bytes_array = image_64_encode.decode("utf-8")
        return bytes_array


    def images_to_bytearray_df(image_filename_list: list):
        df_list = []
        for img_filename in image_filename_list:
            image = open(img_filename, "rb")  # open binary file in read mode
            image_read = image.read()
            df_list.append(convert_image_to_bytearray(image_read))
        return pd.DataFrame(df_list, columns=["image_data"])
    ```

2. ìœ„ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì™€ ë³€í™˜ ì½”ë“œë¥¼ ì´ìš©í•´ `input_sample` ì„ ìƒì„±í•˜ê³  ë©í•‘ëœ ëª¨ë¸ì„ ì´ìš©í•´ ì¶”ë¡ í•©ë‹ˆë‹¤.

    ```python
    from PIL import ImageDraw
    import seaborn as sns

    ## make input sample
    input_sample = images_to_bytearray_df(image_filename_list)

    ## For inference
    pred = serve_model.predict(input_sample)
    predictions = serve_model.revert_predict_to_array(pred)

    ## Load Categories
    cats = dataset.coco.loadCats(dataset.coco.getCatIds())
    cats_palette = sns.color_palette("Set2", len(cats)).as_hex()
    for idx in range(len(cats)):
        cats[idx]["color"] = cats_palette[idx]

    ## Draw inference results
    img = Image.open(sample_image_path)
    for idx in range(len(predictions["boxes"][0])):
        label = predictions["labels"][0][idx]
        score = predictions["scores"][0][idx]
        box = predictions["boxes"][0][idx]
        ## cat = cats[label]
        cat = dataset.coco.loadCats(label.item())[0]

        if score < 0.9:
            continue

        draw = ImageDraw.Draw(img)
        draw.rectangle(box, outline=cat["color"], width = 3)
        draw.text(box, cat["name"], cat["color"])

    imshow(img)
    del draw
    ```

3. ì¶”ë¡  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
   ![predict result](../../assets/object_detection/predict_result.png)

### ëª¨ë¸ ì—…ë¡œë“œ

> ğŸ“˜ ëª¨ë¸ ì—…ë¡œë“œ ë°©ë²•ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°€ì´ë“œëŠ” **[ëª¨ë¸ ì—…ë¡œë“œ](https://docs.mrxrunway.ai/docs/ëª¨ë¸-ì €ì¥)** ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. Runway code snippet ì˜ save modelì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ëª¨ë¸ ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    ```python
    import runway

    del map_score["classes"]
    runway.start_run()
    runway.log_metrics(map_score)

    runway.log_model(model_name="my-detection-model", model=serve_model, input_samples={'predict': input_sample})
    ```

## íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë° ì €ì¥

> ğŸ“˜ íŒŒì´í”„ë¼ì¸ ìƒì„± ë°©ë²•ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°€ì´ë“œëŠ” **[íŒŒì´í”„ë¼ì¸ ìƒì„±](https://dash.readme.com/project/makinarocks-runway/docs/íŒŒì´í”„ë¼ì¸-ìƒì„±)** ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±í•  ì½”ë“œ ì…€ì„ ì„ íƒí•˜ì—¬ ì»´í¬ë„ŒíŠ¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
2. íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±ì´ ì™„ë£Œë˜ë©´, ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ ì •ìƒ ë™ì‘ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. íŒŒì´í”„ë¼ì¸ì˜ ì •ìƒ ë™ì‘ í™•ì¸ í›„, íŒŒì´í”„ë¼ì¸ì„ Runwayì— ì €ì¥í•©ë‹ˆë‹¤.
    1. ì¢Œì¸¡ íŒ¨ë„ ì˜ì—­ì˜ Upload Pipelineì„ í´ë¦­í•©ë‹ˆë‹¤.
    2. Pipeline ì €ì¥ ì˜µì…˜ì„ ì„ íƒí•©ë‹ˆë‹¤.
        1. ì‹ ê·œ ì €ì¥ì˜ ê²½ìš°, New Pipelineì„ ì„ íƒí•©ë‹ˆë‹¤.
        2. ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì˜ ì—…ë°ì´íŠ¸ì¼ ê²½ìš°, Version Updateë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    3. íŒŒì´í”„ë¼ì¸ ì €ì¥ì„ ìœ„í•œ ê°’ì„ ì…ë ¥ í›„, Saveë¥¼ í´ë¦­í•©ë‹ˆë‹¤.
4. Runway í”„ë¡œì íŠ¸ ë©”ë‰´ì—ì„œ Pipeline í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
5. ì €ì¥í•œ íŒŒì´í”„ë¼ì¸ì˜ ì´ë¦„ì„ í´ë¦­í•˜ë©´ íŒŒì´í”„ë¼ì¸ ìƒì„¸ í˜ì´ì§€ë¡œ ì§„ì…í•©ë‹ˆë‹¤.

## ëª¨ë¸ ë°°í¬

> ğŸ“˜ ëª¨ë¸ ë°°í¬ ë°©ë²•ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°€ì´ë“œëŠ” **[ëª¨ë¸ ë°°í¬](https://docs.mrxrunway.ai/docs/%EB%AA%A8%EB%8D%B8-%EB%B0%B0%ED%8F%AC-%EB%B0%8F-%EC%98%88%EC%B8%A1-%EC%9A%94%EC%B2%AD)** ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë°ëª¨ ì‚¬ì´íŠ¸

1. ë°°í¬ëœ ëª¨ë¸ì„ ì‹¤í—˜í•˜ê¸° ìœ„í•œ [ë°ëª¨ ì‚¬ì´íŠ¸](http://demo.service.mrxrunway.ai/object)ì— ì ‘ì†í•©ë‹ˆë‹¤.
2. ë°ëª¨ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ í™”ë©´ì´ ë‚˜ì˜µë‹ˆë‹¤.

    ![demo web](../../assets/object_detection/demo-web.png)

3. API Endpoint, ë°œê¸‰ ë°›ì€ API Token, ì˜ˆì¸¡ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    ![demo fill field](../../assets/object_detection/demo-fill-field.png)

4. ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ![demo result](../../assets/object_detection/demo-result.png)
