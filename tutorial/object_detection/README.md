# Object Detection

<h4 align="center">
    <p>
        <b>ν•κµ­μ–΄</b> |
        <a href="README_en.md">English</a>
    <p>
</h4>

<h3 align="center">
    <p>The MLOps platform to Let your AI run</p>
</h3>

## Introduction

Runwayμ— ν¬ν•¨λ Linkλ¥Ό μ‚¬μ©ν•μ—¬ μ΄λ―Έμ§€ λ¨λΈμ„ ν•™μµν•κ³  μ €μ¥ν•©λ‹λ‹¤.  
μ‘μ„±ν• λ¨λΈ ν•™μµ μ½”λ“λ¥Ό μ¬ν•™μµμ— ν™μ©ν•κΈ° μ„ν•΄ νμ΄ν”„λΌμΈμ„ κµ¬μ„±ν•κ³  μ €μ¥ν•©λ‹λ‹¤.

> π“ λΉ λ¥Έ μ‹¤ν–‰μ„ μ„ν•΄ μ•„λμ μ£Όν”Όν„° λ…ΈνΈλ¶μ„ ν™μ©ν•  μ μμµλ‹λ‹¤.  
> μ•„λμ μ£Όν”Όν„° λ…ΈνΈλ¶μ„ λ‹¤μ΄λ΅λ“ λ°›μ•„ μ‹¤ν–‰ν•  κ²½μ°, "my-detection-model" μ΄λ¦„μ λ¨λΈμ΄ μƒμ„±λμ–΄ Runwayμ— μ €μ¥λ©λ‹λ‹¤.
>
> **[object detection notebook](https://drive.google.com/uc?export=download&id=1WgdswAqXZtRE-BMJXpiFIBYHV-oboV4F)**

![link notebook](../../assets/object_detection/link_pipeline.png)

## Runway

> π“ μ΄ νν† λ¦¬μ–Όμ€ COCO λ°μ΄ν„° μ…‹μ μΌλ¶€λ¥Ό μ‚¬μ©ν•΄ κ°μ²΄ νƒμ§€λ¥Ό μν–‰ν•λ” λ¨λΈμ„ μƒμ„±ν•©λ‹λ‹¤.
>
> COCO μƒν” λ°μ΄ν„°μ…‹μ€ μ•„λ ν•­λ©μ„ ν΄λ¦­ν•μ—¬ λ‹¤μ΄λ΅λ“ ν•  μ μμµλ‹λ‹¤.  
> **[coco-sample-dataset.zip](https://drive.google.com/uc?export=download&id=1TrM3y8aRRmaYnIlDI902p73Lsw0XC89B)**

### λ°μ΄ν„° μ„ΈνΈ μƒμ„±ν•κΈ°

> π“ λ°μ΄ν„°μ…‹ μƒμ„±μ— κ΄€ν• μμ„Έν• λ‚΄μ©μ€ [κ³µμ‹ λ¬Έμ„](https://docs.live.mrxrunway.ai/Guide/ml_development/datasets/dataset-runway/)λ¥Ό μ°Έκ³ ν•μ„Έμ”.

1. Runway ν”„λ΅μ νΈ λ©”λ‰΄μ—μ„ λ°μ΄ν„°μ…‹ νμ΄μ§€λ΅ μ΄λ™ν•©λ‹λ‹¤.
2. λ°μ΄ν„° μ„ΈνΈ λ©”λ‰΄μ—μ„ λ°μ΄ν„° μ„ΈνΈ μƒμ„± λ©”λ‰΄μ— μ§„μ…ν•©λ‹λ‹¤. 
    - μΆμΈ΅ λ°μ΄ν„° μ„ΈνΈ λ©λ΅ μƒλ‹¨ `+` λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
    - μ΄κΈ° ν™”λ©΄μ—μ„ `Create` λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
3. λ‹¤μ΄μ–Όλ΅κ·Έμ—μ„ μƒμ„±ν•  λ°μ΄ν„° μ„ΈνΈμ μ΄λ¦„μ„ μ…λ ¥ ν›„ `Create` λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.

### λ°μ΄ν„° μ„ΈνΈ λ²„μ „ μƒμ„±ν•κΈ°

1. `Versions μ„Ήμ…`μ—μ„  `Create version` λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤. 
2. λ‹¤μ΄μ–Όλ΅κ·Έμ—μ„ `Local file`μ„ μ„ νƒν•©λ‹λ‹¤.
3. μ €μ¥ν•λ” λ°μ΄ν„°μ…‹μ μ΄λ¦„κ³Ό μ„¤λ…μ„ μ…λ ¥ν•©λ‹λ‹¤.
4. λ°μ΄ν„°μ…‹μΌλ΅ μƒμ„±ν•  νμΌμ„ νμΌ νƒμƒ‰κΈ°λ΅ μ„ νƒν•κ±°λ‚, Drag&DropμΌλ΅ μ…λ ¥ν•©λ‹λ‹¤.
5. `Create`λ¥Ό ν΄λ¦­ν•©λ‹λ‹¤.

## Link

### ν¨ν‚¤μ§€ μ„¤μΉ

1. νν† λ¦¬μ–Όμ—μ„ μ‚¬μ©ν•  ν¨ν‚¤μ§€λ¥Ό μ„¤μΉν•©λ‹λ‹¤.
    ```python
    !pip install torch torchvision Pillow seaborn torchmetrics
    ```

### λ°μ΄ν„°

#### λ°μ΄ν„° λ¶λ¬μ¤κΈ°

> π“ λ°μ΄ν„° μ„ΈνΈ λ¶λ¬μ¤λ” λ°©λ²•μ— λ€ν• κµ¬μ²΄μ μΈ κ°€μ΄λ“λ” **[λ°μ΄ν„° μ„ΈνΈ κ°€μ Έμ¤κΈ°](https://docs.live.mrxrunway.ai/Guide/ml_development/dev_instances/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%84%B8%ED%8A%B8_%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0/)** κ°€μ΄λ“ μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

1. λ…ΈνΈλ¶ μ…€ μƒλ‹¨μ **Add Runway Snippet** λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
2. **Import Dataset** λ¥Ό μ„ νƒν•©λ‹λ‹¤. 
3. μ‚¬μ©ν•  λ°μ΄ν„° μ„ΈνΈμ λ²„μ „μ„ μ„ νƒν•κ³  **Save** λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
4. λ²„νΌ ν΄λ¦­ μ‹ λ…ΈνΈλ¶ μ…€ λ‚΄ μ„ νƒν• λ°μ΄ν„° μ„ΈνΈ λ‚΄ νμΌ λ©λ΅μ„ μ΅°νν•  μ μλ” μ¤λ‹ν«μ΄ μ‘μ„±λλ©°, ν•΄λ‹Ή λ°μ΄ν„° μ„ΈνΈ κ²½λ΅λ¥Ό κ°’μΌλ΅ κ°–λ” λ°μ΄ν„° μ„ΈνΈ νλΌλ―Έν„°κ°€ μ¶”κ°€λ©λ‹λ‹¤.  
5. λ°μ΄ν„° μ„ΈνΈλ¥Ό λ¶λ¬μ¤κ³ μ ν•λ” λ…ΈνΈλ¶ μ…€μ—μ„ λ“±λ΅λ λ°μ΄ν„° μ„ΈνΈ νλΌλ―Έν„°μ μ΄λ¦„μ„ μ…λ ¥ν•μ—¬ μ‘μ—…μ— ν™μ©ν•©λ‹λ‹¤.
    ```python
    import os
    from pycocotools.coco import COCO

    # RUNWAY_DATA_PATH was added to pipeline parameters.
    # Pipeline parameters can be used in the cell added as a pipeline component.
    # RUNWAY_DATA_PATH = "/home/jovyan/workspace/dataset/sample-coco"
    config_file = None
    for dirname, _, filenames in os.walk(RUNWAY_DATA_PATH):
        for filename in filenames:
            if filename.endswith(".json"):
                config_file = os.path.join(dirname, filename)

    if config_file is None:
        raise ValueError("Can't find config file in given dataset")

    coco = COCO(config_file)
    ```

#### μμ  λ°μ΄ν„° μ¶”μ¶

1. μƒν” λ°μ΄ν„° ν•λ‚λ¥Ό μ¶”μ¶ ν›„ μ΄λ―Έμ§€λ¥Ό ν™•μΈν•©λ‹λ‹¤.

    ```python
    from pathlib import Path
    from matplotlib.pyplot import imshow
    from PIL import Image


    sample_image_path = Path(RUNWAY_DATA_PATH).parent / "000000000139.jpg"
    image_filename_list = [sample_image_path]

    img = Image.open(sample_image_path)
    imshow(img)
    ```

    ![sample image](../../assets/object_detection/sample_image.png)

### ν•™μµ

#### COCO λ°μ΄ν„°μ…‹

1. λ¨λΈμ„ ν•™μµν•κΈ° μ„ν•΄μ„ pytorch μ—μ„ μ κ³µν•λ” Dataset μ„ μƒμ„±ν•©λ‹λ‹¤.

    ```python
    from PIL import Image
    from pathlib import Path
    from pycocotools.coco import COCO
    import torch
    from torch.utils.data import Dataset
    from torchvision import transforms as T


    def get_transforms():
        transforms = []
        transforms.append(T.ToTensor())
        return T.Compose(transforms)


    def collate_fn(batch):
        return tuple(zip(*batch))


    class COCODataset(Dataset):
        def __init__(self, data_root, coco, transforms=None):
            self.data_root = Path(data_root)
            self.transforms = transforms
            # pre-loaded variables
            self.coco = coco
            self.ids = list(sorted(self.coco.imgs.keys()))

        def __getitem__(self, index):
            ## refer to https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html
            img_id = self.ids[index]
            ann_ids = self.coco.getAnnIds(imgIds=img_id)
            ann = self.coco.loadAnns(ann_ids)
            img_path = self.data_root / self.coco.loadImgs(img_id)[0]["file_name"]
            img = Image.open(img_path)
            num_objs = len(ann)

            boxes = []
            for i in range(num_objs):
                boxes.append([
                    ann[i]["bbox"][0],
                    ann[i]["bbox"][1],
                    ann[i]["bbox"][2] + ann[i]["bbox"][0],
                    ann[i]["bbox"][3] + ann[i]["bbox"][1],
                ])

            areas = []
            for i in range(num_objs):
                areas.append(ann[i]["area"])

            target = {
                "boxes": torch.as_tensor(boxes, dtype=torch.float32),
                "labels": torch.ones((num_objs,), dtype=torch.int64),
                "image_id": torch.tensor([img_id]),
                "area": torch.as_tensor(areas, dtype=torch.float32),
                "iscrowd": torch.zeros((num_objs,), dtype=torch.int64),
            }

            ## transform image
            if self.transforms is not None:
                img = self.transforms(img)

            return img, target

        def __len__(self):
            return len(self.ids)
    ```

2. μ„ μ–Έν• λ°μ΄ν„°λ¥Ό μ΄μ©ν•΄ λ°μ΄ν„° λ΅λ”λ¥Ό μƒμ„±ν•©λ‹λ‹¤.

    ```python
    from torch.utils.data import DataLoader

    ## Define Train dataset
    data_root = Path(RUNWAY_DATA_PATH).parent
    dataset = COCODataset(data_root, coco, get_transforms())

    data_loader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=True,
        num_workers=4,
        collate_fn=collate_fn
    )
    ```

### λ¨λΈ μ„ μ–Έ

1. ν•™μµμ— μ‚¬μ©ν•  λ¨λΈμ„ μ„ μ–Έν•©λ‹λ‹¤. νν† λ¦¬μ–Όμ—μ„λ” pytorch μ `fasterrcnn_resnet50_fpn` λ¨λΈμ„ μ‚¬μ©ν•©λ‹λ‹¤.
    ```python
    import torch
    from torchvision.models.detection import fasterrcnn_resnet50_fpn


    # Define local variables
    print(torch.cuda.is_available())
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

    try:
        entrypoints = torch.hub.list('pytorch/vision', force_reload=True)
        model = fasterrcnn_resnet50_fpn(weights="DEFAULT").to(device)
    except:
        model = fasterrcnn_resnet50_fpn(weights=None, weights_backbone=None).to(device)
    ```

### λ¨λΈ ν•™μµ

> π“ Link νλΌλ―Έν„° λ“±λ΅ κ°€μ΄λ“λ” **[νμ΄ν”„λΌμΈ νλΌλ―Έν„° μ„¤μ •](https://docs.live.mrxrunway.ai/Guide/ml_development/dev_instances/%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8_%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0_%EC%84%A4%EC%A0%95/)** λ¬Έμ„μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.ν•  μ μμµλ‹λ‹¤.

1. λ¨λΈμ„ ν•™μµν•  Epoch μ„ μ„¤μ •ν•  μ μλ„λ΅ Link νλΌλ―Έν„°λ΅ N_EPOCHS μ— 1μ„ λ“±λ΅ν•©λ‹λ‹¤.
2. μ„ μ–Έν• λ¨λΈμ„ μ„μ—μ„ λ§λ“  λ°μ΄ν„° λ΅λ”λ¥Ό ν†µν•΄ ν•™μµν•κ³  λ¨λΈμ μ„±λ¥μ„ ν‰κ°€ν•©λ‹λ‹¤.

    ```python
    import torch.optim as optim
    from torchmetrics.detection import MeanAveragePrecision

    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.SGD(params, lr=1e-5)

    model.train()
    for epoch in range(N_EPOCHS):
        for imgs, annotations in data_loader:
            imgs = list(img.to(device) for img in imgs)
            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]
            loss_dict = model(imgs, annotations)
            losses = sum(loss for loss in loss_dict.values())

            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

    map_metric = MeanAveragePrecision().to(device)
    model.eval()
    with torch.no_grad():
        preds = []
        annos = []
        for imgs, annotations in data_loader:
            pred = model(list(img.to(device) for img in imgs))
            anno = [{k: v.to(device) for k, v in t.items()} for t in annotations]
            preds.extend(pred)
            annos.extend(anno)

    map_metric.update(preds, annos)
    map_score = map_metric.compute()

    torch.cuda.empty_cache()
    ```

### λ¨λΈ μ¶”λ΅ 

#### λ¨λΈ λ©ν•‘ ν΄λμ¤ μ„ μ–Έ

1. ν•™μµλ λ¨λΈμ„ μ„λΉ™ν•  μ μλ„λ΅ ModelWrapperλ¥Ό μ‘μ„±ν•©λ‹λ‹¤.
    ```python
    import io
    import base64

    import torch
    import pandas as pd
    import numpy as np
    from torchvision import transforms
    from PIL import Image, ImageDraw, ImageFont


    class ModelWrapper:
        def __init__(self, model, device):
            self.model = model
            self.device = device

        def bytesarray_to_tensor(self, bytes_array: str):
            # input : "utf-8" decoded bytes_array
            encoded_bytes_array = bytes_array.encode("utf-8")
            # decode encoded_bytes_array with ascii code
            img_64_decode = base64.b64decode(encoded_bytes_array)
            # get image file and transform to tensor
            image_from_bytes = Image.open(io.BytesIO(img_64_decode))
            return transforms.ToTensor()(image_from_bytes).to(self.device)

        def numpy_to_bytesarray(self, numpy_array):
            numpy_array_bytes_array = numpy_array.tobytes()
            numpy_array_64_encode = base64.b64encode(numpy_array_bytes_array)
            bytes_array = numpy_array_64_encode.decode("utf-8")
            return bytes_array

        def draw_detection(self, img_tensor, bboxes, labels, scores, out_img_file):
            """Draw detection result."""
            img_array = img_tensor.permute(1, 2, 0).numpy() * 255
            img = Image.fromarray(img_array.astype(np.uint8))
            
            draw = ImageDraw.Draw(img)    
            font = ImageFont.load_default()
            bboxes = bboxes.cpu().numpy().astype(np.int32)
            labels = labels.cpu().numpy()
            scores = scores.cpu().numpy()
            for box, label, score in zip(bboxes, labels, scores):        
                draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline="red", width=1)  
                text = f"{label}: {score:.2f}"
                draw.text((box[0], box[1]), text, fill="red", font=font)
            img.save(out_img_file)
            return img

        @torch.no_grad()
        def predict(self, df):
            self.model.eval()
            # df is 1-d dataframe with bytes array
            tensor_list = list((map(self.bytesarray_to_tensor, df.squeeze(axis=1).to_list())))

            pred_images = []
            pred_image_shape_c = []
            pred_image_shape_h = []
            pred_image_shape_w = []
            pred_image_dtypes = []

            boxes = []
            labels = []
            scores = []

            boxes_dtypes = []
            labels_dtypes = []
            scores_dtypes = []

            for img in tensor_list:
                output = self.model(img.unsqueeze(0))
                detect_img = self.draw_detection(
                    img_tensor=img,
                    bboxes=output[0]["boxes"],
                    labels=output[0]["labels"],
                    scores=output[0]["scores"],
                    out_img_file="test.png",
                )
                detect_img = np.array(detect_img)
                h, w, c = detect_img.shape
                box = output[0]["boxes"].cpu().numpy()
                label = output[0]["labels"].cpu().numpy()
                score = output[0]["scores"].cpu().numpy()

                pred_images += [detect_img]
                boxes += [box]
                labels += [label]
                scores += [score]

                pred_image_shape_c += [c]
                pred_image_shape_h += [h]
                pred_image_shape_w += [w]

                pred_image_dtypes += [str(detect_img.dtype)]
                boxes_dtypes += [str(box.dtype)]
                labels_dtypes += [str(label.dtype)]
                scores_dtypes += [str(score.dtype)]

                torch.cuda.empty_cache()

            meta = pd.DataFrame({
                "pred_image_shape_c": pred_image_shape_c,
                "pred_image_shape_h": pred_image_shape_h,
                "pred_image_shape_w": pred_image_shape_w,
                "output_dtype": pred_image_dtypes,
                "boxes_dtypes": boxes_dtypes,
                "labels_dtypes": labels_dtypes,
                "scores_dtypes": scores_dtypes,
            })
            img_byte = pd.DataFrame({
                "output": pred_images,
                "boxes": boxes,
                "labels": labels,
                "scores": scores,
                # "true": tensor_list,
            }).applymap(lambda x: self.numpy_to_bytesarray(x))
            return pd.concat([meta, img_byte], axis="columns")
    ```

#### μƒν” μ΄λ―Έμ§€ μ¶”λ΅ 

1. Runway μ—μ„λ” API μ„λΉ™μ„ μ„ν• μ…λ ¥κ³Ό μ¶λ ¥μ„ Dataframe ν•μ‹λ§ μ§€μ›ν•κ³  μμµλ‹λ‹¤. μ΄λ¥Ό μ„ν•΄μ„ μ…λ ¥ μ΄λ―Έμ§€λ¥Ό bytearray λ΅ λ³€ν™ν•΄μ£Όλ” μ½”λ“λ¥Ό μ‘μ„±ν•©λ‹λ‹¤.

    ```python
    import base64
    import pandas as pd


    def convert_image_to_bytearray(img_binary):
        image_64_encode = base64.b64encode(img_binary)
        bytes_array = image_64_encode.decode("utf-8")
        return bytes_array


    def images_to_bytearray_df(image_filename_list: list):
        df_list = []
        for img_filename in image_filename_list:
            image = open(img_filename, "rb")  # open binary file in read mode
            image_read = image.read()
            df_list.append(convert_image_to_bytearray(image_read))
        return pd.DataFrame(df_list, columns=["image_data"])
    ```

2. μ„μ—μ„ μ‚¬μ©ν• λ°μ΄ν„°μ™€ λ³€ν™ μ½”λ“λ¥Ό μ΄μ©ν•΄ `input_sample` μ„ μƒμ„±ν•κ³  λ¨λΈμ„ λ©ν•‘ν• κ°μ²΄λ¥Ό μ΄μ©ν•΄ μ¶”λ΅ ν•©λ‹λ‹¤.

    ```python
    model = model.cpu()
    device = "cpu"
    serve_model = ModelWrapper(model=model, device=device)

    # make input sample
    input_sample = images_to_bytearray_df(image_filename_list)

    # For inference
    pred = serve_model.predict(input_sample)

    output = pred.loc[0]
    data, dtype = output["output"], output["output_dtype"]
    c, h, w = output["pred_image_shape_c"], output["pred_image_shape_h"], output["pred_image_shape_w"]

    type_dict = {"uint8": np.uint8, "float32": np.float32, "int64": np.int64}
    pred_decode = base64.b64decode(data)
    pred_array = np.frombuffer(pred_decode, dtype=type_dict[dtype])

    img = Image.fromarray(pred_array.reshape(h, w, c))

    imshow(img)
    ```

3. μ¶”λ΅  κ²°κ³Όλ¥Ό ν™•μΈν•©λ‹λ‹¤.
   ![predict result](../../assets/object_detection/predict_result.png)

### λ¨λΈ μ—…λ΅λ“

> π“ λ¨λΈ μ—…λ΅λ“ λ°©λ²•μ— λ€ν• κµ¬μ²΄μ μΈ κ°€μ΄λ“λ” **[λ¨λΈ μ—…λ΅λ“](https://docs.mrxrunway.ai/docs/λ¨λΈ-μ €μ¥)** λ¬Έμ„μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

1. Runway code snippet μ save modelμ„ μ‚¬μ©ν•΄ λ¨λΈμ„ μ €μ¥ν•λ” μ½”λ“λ¥Ό μƒμ„±ν•©λ‹λ‹¤. κ·Έλ¦¬κ³  λ¨λΈ κ³Ό κ΄€λ ¨λ μ •λ³΄λ¥Ό μ €μ¥ν•©λ‹λ‹¤.
    ```python
    import runway

    del map_score["classes"]
    runway.start_run()
    runway.log_metrics(map_score)

    runway.log_model(model_name="my-detection-model", model=serve_model, input_samples={'predict': input_sample})
    ```

## νμ΄ν”„λΌμΈ κµ¬μ„± λ° μ €μ¥

> π“ νμ΄ν”„λΌμΈ μƒμ„± λ°©λ²•μ— λ€ν• κµ¬μ²΄μ μΈ κ°€μ΄λ“λ” **[νμ΄ν”„λΌμΈ μƒμ„±](https://dash.readme.com/project/makinarocks-runway/docs/νμ΄ν”„λΌμΈ-μƒμ„±)** λ¬Έμ„μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

1. **Link**μ—μ„ νμ΄ν”„λΌμΈμ„ μ‘μ„±ν•κ³  μ •μƒ μ‹¤ν–‰ μ—¬λ¶€λ¥Ό ν™•μΈν•©λ‹λ‹¤.
2. μ •μƒ μ‹¤ν–‰ ν™•μΈ ν›„, Link pipeline ν¨λ„μ **Upload pipeline** λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
3. **New Pipeline** λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
4. **Pipeline** ν•„λ“μ— Runwayμ— μ €μ¥ν•  μ΄λ¦„μ„ μ‘μ„±ν•©λ‹λ‹¤.
5. **Pipeline version** ν•„λ“μ—λ” μλ™μΌλ΅ λ²„μ „ 1μ΄ μ„ νƒλ©λ‹λ‹¤.
6. **Upload** λ²„νΌμ„ ν΄λ¦­ν•©λ‹λ‹¤.
7. μ—…λ΅λ“κ°€ μ™„λ£λλ©΄ ν”„λ΅μ νΈ λ‚΄ Pipeline νμ΄μ§€μ— μ—…λ΅λ“ν• νμ΄ν”„λΌμΈ ν•­λ©μ΄ ν‘μ‹λ©λ‹λ‹¤.


## λ¨λΈ λ°°ν¬

> π“ λ¨λΈ λ°°ν¬ λ°©λ²•μ— λ€ν• κµ¬μ²΄μ μΈ κ°€μ΄λ“λ” **[λ¨λΈ λ°°ν¬](https://docs.live.mrxrunway.ai/Guide/ml_serving/model_deployments/%EB%AA%A8%EB%8D%B8_%EB%B0%B0%ED%8F%AC/)** λ¬Έμ„μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

## λ°λ¨ μ‚¬μ΄νΈ

1. λ°°ν¬λ λ¨λΈμ„ μ‹¤ν—ν•κΈ° μ„ν• [λ°λ¨ μ‚¬μ΄νΈ](http://demo.service.mrxrunway.ai/object)μ— μ ‘μ†ν•©λ‹λ‹¤.
2. λ°λ¨μ‚¬μ΄νΈμ— μ ‘μ†ν•λ©΄ μ•„λμ™€ κ°™μ€ ν™”λ©΄μ΄ λ‚μµλ‹λ‹¤.

    ![demo web](../../assets/object_detection/demo-web.png)

3. API Endpoint, λ°κΈ‰ λ°›μ€ API Token, μμΈ΅μ— μ‚¬μ©ν•  μ΄λ―Έμ§€λ¥Ό μ—…λ΅λ“ν•©λ‹λ‹¤.

    ![demo fill field](../../assets/object_detection/demo-fill-field.png)

4. κ²°κ³Όλ¥Ό λ°›μ„ μ μμµλ‹λ‹¤.

    ![demo result](../../assets/object_detection/demo-result.png)
